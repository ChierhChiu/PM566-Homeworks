---
title: "HW4"
author: "Chi-Erh Chiu"
format: html
embed-resources: true
---

### HPC

#### Make things run faster

```{r}
# Total for each row
fun1 <- function(mat) {
  n <- nrow(mat)
  ans <- double(n) 
  for (i in 1:n) {
    ans[i] <- sum(mat[i, ])
  }
  ans
}

fun1alt <- function(mat) {
  rowSums(mat)
}

# running cumulative sum by row
fun2 <- function(mat) {
  n <- nrow(mat)
  k <- ncol(mat)
  ans <- mat
  for (i in 1:n) {
    for (j in 2:k) {
      ans[i,j] <- mat[i, j] + ans[i, j - 1]
    }
  }
  ans
}

fun2alt <- function(mat) {
  t(apply(mat, 1, cumsum))
}
```

#### Question 1

```{r}
# Use the data with this code
set.seed(2315)
dat <- matrix(rnorm(200 * 100), nrow = 200)

all.equal(fun1(dat), fun1alt(dat))
all.equal(fun2(dat), fun2alt(dat))

# Test for the first
microbenchmark::microbenchmark(
  fun1(dat),
  fun1alt(dat), unit = "relative"
)

# Test for the second
microbenchmark::microbenchmark(
  fun2(dat),
  fun2alt(dat), unit = "relative"
)
```

Based on the microbenchmark results, when we test for the first, fun1alt(dat) is approximatley 27 times faster than the original fun1(dat). And if we test for the second, we can see that fun2alt(dat) is approximately 4 times faster than the original fun2(dat).

#### Make things run faster with parallel computing

```{r}
sim_pi <- function(n = 1000, i = NULL) {
  p <- matrix(runif(n*2), ncol = 2)
  mean(rowSums(p^2) < 1) * 4
}

# Here is an example of the run
set.seed(156)
sim_pi(1000) # 3.132
```

```{r}
# This runs the simulation a 4,000 times, each with 10,000 points
set.seed(1231)
system.time({
  ans <- unlist(lapply(1:4000, sim_pi, n = 10000))
  print(mean(ans))
})
```

#### Question 2

```{r}
library(parallel)

system.time({
  cl <- makeCluster(detectCores() - 1)
  clusterExport(cl, "sim_pi")
  ans <- unlist(parLapply(cl, 1:4000, sim_pi, n = 10000))
  print(mean(ans))
  stopCluster(cl)
})

```

Using the parLapply, it took about 1/2 of the time compared to the original lapply.

### SQL

```{r}
library(RSQLite)
library(DBI)

# Initialize a temporary in memory database
con <- dbConnect(SQLite(), ":memory:")

# Download tables
film <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film.csv")
film_category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film_category.csv")
category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/category.csv")

# Copy data.frames to database
dbWriteTable(con, "film", film)
dbWriteTable(con, "film_category", film_category)
dbWriteTable(con, "category", category)
```

#### Question 3

```{sql connection=con}
SELECT rating, COUNT(*) AS count
FROM film
GROUP BY rating
```

The number of movies available for each rating category is 180 for G, 210 for NC-17, 194 for PG, 223 for PG-13, 195 for R.

#### Question 4

```{sql connection=con}
SELECT rating, 
       AVG(replacement_cost) AS avg_replacement_cost, 
       AVG(rental_rate) AS avg_rental_rate
FROM film
GROUP BY rating
```

The average replacement cost for G is approximately(\~) \$20.12, for NC-17 is \~ \$20.14, for PG is \~ \$18.96, for PG-13 is \~ \$20.40, and for R is \~ \$20.23. Overall in each ratings, the average replacement cost is approximately \$20, where PG's average replacement cost being the lowest.

In addition, the overall rating category average rental rate is approximately \$3. The average rental rate for G is \~\$2.91, for NC-17 is \~\$2.97, for PG is \~\$ 3.05, for PG-13 is \~\$3.03, and for R is \~\$2.94.

#### Question 5

```{sql connection=con}
SELECT t1.category_id, COUNT(*) AS count
FROM film_category AS t1
JOIN film AS t2 ON t1.film_id = t2.film_id
GROUP BY t1.category_id
```

#### Question 6

```{sql connection=con}
SELECT t3.name, COUNT(*) AS count
FROM film_category AS t1
JOIN film AS t2 ON t1.film_id = t2.film_id
JOIN category AS t3 ON t1.category_id = t3.category_id
GROUP BY t3.name
ORDER BY count DESC
```

Sports is the most popular category among the film genres.
